starting_actors = ["delegation_network_coordinator"]

##############################
# TUI Specific Config ########
##############################

# These are the default bindings - not required but shown here for easy customization
[tui.dashboard.key_bindings]
"ctrl-c" = "Exit"
"esc" = "InterruptAgent"

[tui.chat.key_bindings]
"ctrl-a" = "Assist"
"ctrl-t" = "ToggleToolExpansion"

[tui.graph.key_bindings]
"shift-down" = "SelectDown"
"shift-up" = "SelectUp"

##############################
# Actors Config ##############
##############################

[actors.delegation_network_coordinator]
source = { path = "/Users/silasmarvin/github/wasmind/actors/delegation_network", package = "crates/delegation_network_coordinator" }

[actor_overrides.main_manager_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.sub_manager_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.worker_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.check_health_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.manager_perspective_reviewer_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.strategic_plan_advisor_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.code_reuse_advisor_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.idiomatic_code_advisor_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.idiomatic_code_approver_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.redundancy_approver_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.correctness_logic_approver_assistant.config]
model_name = "qwen/qwen3-coder"

[actor_overrides.conversation_compaction.config]
token_threshold = 50000
model_name = "qwen/qwen3-coder"

##############################
# LiteLLM Config #############
##############################

[litellm]
image = "ghcr.io/berriai/litellm:main-latest"
port = 4000
container_name = "wasmind-litellm"

# [[litellm.models]]
# model_name = "gpt-oss-120b"
#
# [litellm.models.litellm_params]
# model = "openrouter/openai/gpt-oss-120b"
# api_key = "os.environ/OPENROUTER_API_KEY"
# provider = { only = ["cerebras"] }
#
# [[litellm.models]]
# model_name = "gemini-2.5-flash"
#
# [litellm.models.litellm_params]
# model = "openrouter/google/gemini-2.5-flash"
# api_key = "os.environ/OPENROUTER_API_KEY"

[[litellm.models]]
model_name = "openai/gpt-5-mini"

[litellm.models.litellm_params]
model = "openai/gpt-5-mini"
api_key = "os.environ/OPENAI_API_KEY"

[[litellm.models]]
model_name = "qwen/qwen3-coder"

[litellm.models.litellm_params]
model = "openrouter/qwen/qwen3-coder"
api_key = "os.environ/OPENROUTER_API_KEY"
provider = { only = ["fireworks", "cerebras"] }
